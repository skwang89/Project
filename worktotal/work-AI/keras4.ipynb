{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"keras4.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1NyK0igCevvFRTCXR__ZhIWlUjkS-fRul","authorship_tag":"ABX9TyMlYD6uGfIAweYkP+Ugs/Ei"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"vARgyhqCco84","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1600588246308,"user_tz":-540,"elapsed":7556,"user":{"displayName":"Sung-kwang Kim","photoUrl":"","userId":"00988667817378607569"}},"outputId":"13dbc0ea-f030-4eab-a95c-01c43710baf5"},"source":["# 포도주로 만든 와인은 고대 그리스 시대부터 서양 음식의 기본이 된 오랜 양조주 이다.\n","# 와인은 빛깔에 따라 맑고 투명한 화이트 와인과 붉은색을 띠는 레드 와인으로 구분된다.\n","# 실습에 사용하게될 데이터는 포르투갈 서북쪽의 대서양을 맞닿고 위치한 베르드(Vinho Verde) 지방에서\n","# 만들어진 와인을 측정한 데이터 이다.\n","\n","# 레드와인 샘플 1,599개의 등급과 맛, 산도를 측정해 분석하고 화이트와인 샘플 4,898개를 마찬가지로 분석\n","# 해서 만들어진 데이터 이다.\n","\n","# 레드와인과 화이트와인의 특징을 학습하고 분류하는 예제\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","import pandas as pd\n","import numpy\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","\n","# seed 값 설정: 실행할 때마다 같은 결과가 나오도록 설정\n","seed=0\n","numpy.random.seed(seed)\n","tf.random.set_seed(seed)\n","\n","# 데이터 로딩\n","df=pd.read_csv('/content/drive/My Drive/workspace-total/workspace-python/2020_07_27_t2/dataset/wine.csv', header=None)\n","print(df)     # [6497 rows x 13 columns]\n","\n","dataset = df.values   # 데이터 프레임의 데이터만 불러와서 dataset을 만듬\n","x=dataset[:,0:12]     # 와인의 특징 12개의 열 추출(0~11)\n","y=dataset[:,12]       # 12번째 열(1:레드와인, 0:화이트와인)\n","\n","# 모델 설정\n","model=Sequential()\n","model.add(Dense(30, input_dim=12, activation='relu'))   # 입력층: 출력 node 30개, 이력 node 12개\n","model.add(Dense(12, activation='relu'))       # 은닉층: 출력 node 12개\n","model.add(Dense(8, activation='relu'))        # 은닉층: 출력 node 8개\n","model.add(Dense(1, activation='sigmoid'))     # 출력층: 출력 node 1개(이중분류)\n","\n","# 모델 컴파일\n","model.compile(loss='binary_crossentropy',     # 오차함수: 이중분류 - binary_croosentropy\n","              optimizer='adam',\n","              metrics=['accuracy'])\n","\n","# 모델 실행\n","model.fit(x, y, epochs=200, batch_size=200)   # 학습횟수(epochs): 200회\n","\n","# 결과 출력\n","print('\\n Accuracy: %.4f' %(model.evaluate(x,y)[1]))\n","\n","# 출력 결과\n","#  Accuracy: 0.9871\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["        0     1     2    3      4     5   ...       7     8     9     10  11  12\n","0      7.4  0.70  0.00  1.9  0.076  11.0  ...  0.99780  3.51  0.56   9.4   5   1\n","1      7.8  0.88  0.00  2.6  0.098  25.0  ...  0.99680  3.20  0.68   9.8   5   1\n","2      7.8  0.76  0.04  2.3  0.092  15.0  ...  0.99700  3.26  0.65   9.8   5   1\n","3     11.2  0.28  0.56  1.9  0.075  17.0  ...  0.99800  3.16  0.58   9.8   6   1\n","4      7.4  0.70  0.00  1.9  0.076  11.0  ...  0.99780  3.51  0.56   9.4   5   1\n","...    ...   ...   ...  ...    ...   ...  ...      ...   ...   ...   ...  ..  ..\n","6492   6.2  0.21  0.29  1.6  0.039  24.0  ...  0.99114  3.27  0.50  11.2   6   0\n","6493   6.6  0.32  0.36  8.0  0.047  57.0  ...  0.99490  3.15  0.46   9.6   5   0\n","6494   6.5  0.24  0.19  1.2  0.041  30.0  ...  0.99254  2.99  0.46   9.4   6   0\n","6495   5.5  0.29  0.30  1.1  0.022  20.0  ...  0.98869  3.34  0.38  12.8   7   0\n","6496   6.0  0.21  0.38  0.8  0.020  22.0  ...  0.98941  3.26  0.32  11.8   6   0\n","\n","[6497 rows x 13 columns]\n","Epoch 1/200\n","33/33 [==============================] - 0s 715us/step - loss: 0.3792 - accuracy: 0.8518\n","Epoch 2/200\n","33/33 [==============================] - 0s 705us/step - loss: 0.2663 - accuracy: 0.9147\n","Epoch 3/200\n","33/33 [==============================] - 0s 669us/step - loss: 0.2403 - accuracy: 0.9206\n","Epoch 4/200\n","33/33 [==============================] - 0s 699us/step - loss: 0.2150 - accuracy: 0.9283\n","Epoch 5/200\n","33/33 [==============================] - 0s 717us/step - loss: 0.2020 - accuracy: 0.9327\n","Epoch 6/200\n","33/33 [==============================] - 0s 705us/step - loss: 0.1954 - accuracy: 0.9334\n","Epoch 7/200\n","33/33 [==============================] - 0s 677us/step - loss: 0.1902 - accuracy: 0.9355\n","Epoch 8/200\n","33/33 [==============================] - 0s 694us/step - loss: 0.1856 - accuracy: 0.9360\n","Epoch 9/200\n","33/33 [==============================] - 0s 712us/step - loss: 0.1815 - accuracy: 0.9361\n","Epoch 10/200\n","33/33 [==============================] - 0s 716us/step - loss: 0.1788 - accuracy: 0.9369\n","Epoch 11/200\n","33/33 [==============================] - 0s 703us/step - loss: 0.1738 - accuracy: 0.9381\n","Epoch 12/200\n","33/33 [==============================] - 0s 701us/step - loss: 0.1695 - accuracy: 0.9403\n","Epoch 13/200\n","33/33 [==============================] - 0s 706us/step - loss: 0.1653 - accuracy: 0.9410\n","Epoch 14/200\n","33/33 [==============================] - 0s 710us/step - loss: 0.1575 - accuracy: 0.9427\n","Epoch 15/200\n","33/33 [==============================] - 0s 737us/step - loss: 0.1526 - accuracy: 0.9451\n","Epoch 16/200\n","33/33 [==============================] - 0s 762us/step - loss: 0.1505 - accuracy: 0.9461\n","Epoch 17/200\n","33/33 [==============================] - 0s 859us/step - loss: 0.1408 - accuracy: 0.9471\n","Epoch 18/200\n","33/33 [==============================] - 0s 787us/step - loss: 0.1382 - accuracy: 0.9489\n","Epoch 19/200\n","33/33 [==============================] - 0s 721us/step - loss: 0.1329 - accuracy: 0.9501\n","Epoch 20/200\n","33/33 [==============================] - 0s 835us/step - loss: 0.1300 - accuracy: 0.9514\n","Epoch 21/200\n","33/33 [==============================] - 0s 756us/step - loss: 0.1264 - accuracy: 0.9524\n","Epoch 22/200\n","33/33 [==============================] - 0s 732us/step - loss: 0.1215 - accuracy: 0.9535\n","Epoch 23/200\n","33/33 [==============================] - 0s 720us/step - loss: 0.1217 - accuracy: 0.9558\n","Epoch 24/200\n","33/33 [==============================] - 0s 744us/step - loss: 0.1177 - accuracy: 0.9588\n","Epoch 25/200\n","33/33 [==============================] - 0s 796us/step - loss: 0.1140 - accuracy: 0.9577\n","Epoch 26/200\n","33/33 [==============================] - 0s 754us/step - loss: 0.1110 - accuracy: 0.9611\n","Epoch 27/200\n","33/33 [==============================] - 0s 773us/step - loss: 0.1089 - accuracy: 0.9586\n","Epoch 28/200\n","33/33 [==============================] - 0s 796us/step - loss: 0.1064 - accuracy: 0.9626\n","Epoch 29/200\n","33/33 [==============================] - 0s 759us/step - loss: 0.1131 - accuracy: 0.9620\n","Epoch 30/200\n","33/33 [==============================] - 0s 779us/step - loss: 0.1031 - accuracy: 0.9640\n","Epoch 31/200\n","33/33 [==============================] - 0s 909us/step - loss: 0.1028 - accuracy: 0.9649\n","Epoch 32/200\n","33/33 [==============================] - 0s 908us/step - loss: 0.1027 - accuracy: 0.9655\n","Epoch 33/200\n","33/33 [==============================] - 0s 925us/step - loss: 0.0949 - accuracy: 0.9701\n","Epoch 34/200\n","33/33 [==============================] - 0s 759us/step - loss: 0.0942 - accuracy: 0.9709\n","Epoch 35/200\n","33/33 [==============================] - 0s 771us/step - loss: 0.0920 - accuracy: 0.9691\n","Epoch 36/200\n","33/33 [==============================] - 0s 1ms/step - loss: 0.0903 - accuracy: 0.9714\n","Epoch 37/200\n","33/33 [==============================] - 0s 772us/step - loss: 0.0987 - accuracy: 0.9686\n","Epoch 38/200\n","33/33 [==============================] - 0s 715us/step - loss: 0.0868 - accuracy: 0.9732\n","Epoch 39/200\n","33/33 [==============================] - 0s 764us/step - loss: 0.0947 - accuracy: 0.9692\n","Epoch 40/200\n","33/33 [==============================] - 0s 743us/step - loss: 0.0888 - accuracy: 0.9704\n","Epoch 41/200\n","33/33 [==============================] - 0s 743us/step - loss: 0.0913 - accuracy: 0.9697\n","Epoch 42/200\n","33/33 [==============================] - 0s 803us/step - loss: 0.0869 - accuracy: 0.9720\n","Epoch 43/200\n","33/33 [==============================] - 0s 804us/step - loss: 0.0820 - accuracy: 0.9741\n","Epoch 44/200\n","33/33 [==============================] - 0s 814us/step - loss: 0.0842 - accuracy: 0.9741\n","Epoch 45/200\n","33/33 [==============================] - 0s 839us/step - loss: 0.0837 - accuracy: 0.9726\n","Epoch 46/200\n","33/33 [==============================] - 0s 806us/step - loss: 0.0821 - accuracy: 0.9749\n","Epoch 47/200\n","33/33 [==============================] - 0s 840us/step - loss: 0.0785 - accuracy: 0.9763\n","Epoch 48/200\n","33/33 [==============================] - 0s 921us/step - loss: 0.0821 - accuracy: 0.9738\n","Epoch 49/200\n","33/33 [==============================] - 0s 777us/step - loss: 0.0784 - accuracy: 0.9751\n","Epoch 50/200\n","33/33 [==============================] - 0s 694us/step - loss: 0.0751 - accuracy: 0.9769\n","Epoch 51/200\n","33/33 [==============================] - 0s 760us/step - loss: 0.0745 - accuracy: 0.9778\n","Epoch 52/200\n","33/33 [==============================] - 0s 783us/step - loss: 0.0786 - accuracy: 0.9746\n","Epoch 53/200\n","33/33 [==============================] - 0s 673us/step - loss: 0.0768 - accuracy: 0.9777\n","Epoch 54/200\n","33/33 [==============================] - 0s 697us/step - loss: 0.0714 - accuracy: 0.9778\n","Epoch 55/200\n","33/33 [==============================] - 0s 708us/step - loss: 0.0726 - accuracy: 0.9778\n","Epoch 56/200\n","33/33 [==============================] - 0s 734us/step - loss: 0.0747 - accuracy: 0.9769\n","Epoch 57/200\n","33/33 [==============================] - 0s 702us/step - loss: 0.0729 - accuracy: 0.9768\n","Epoch 58/200\n","33/33 [==============================] - 0s 698us/step - loss: 0.0709 - accuracy: 0.9781\n","Epoch 59/200\n","33/33 [==============================] - 0s 714us/step - loss: 0.0735 - accuracy: 0.9760\n","Epoch 60/200\n","33/33 [==============================] - 0s 710us/step - loss: 0.0724 - accuracy: 0.9778\n","Epoch 61/200\n","33/33 [==============================] - 0s 738us/step - loss: 0.0690 - accuracy: 0.9774\n","Epoch 62/200\n","33/33 [==============================] - 0s 671us/step - loss: 0.0718 - accuracy: 0.9783\n","Epoch 63/200\n","33/33 [==============================] - 0s 728us/step - loss: 0.0701 - accuracy: 0.9794\n","Epoch 64/200\n","33/33 [==============================] - 0s 710us/step - loss: 0.0687 - accuracy: 0.9778\n","Epoch 65/200\n","33/33 [==============================] - 0s 769us/step - loss: 0.0709 - accuracy: 0.9774\n","Epoch 66/200\n","33/33 [==============================] - 0s 745us/step - loss: 0.0663 - accuracy: 0.9791\n","Epoch 67/200\n","33/33 [==============================] - 0s 776us/step - loss: 0.0650 - accuracy: 0.9798\n","Epoch 68/200\n","33/33 [==============================] - 0s 738us/step - loss: 0.0660 - accuracy: 0.9805\n","Epoch 69/200\n","33/33 [==============================] - 0s 908us/step - loss: 0.0661 - accuracy: 0.9809\n","Epoch 70/200\n","33/33 [==============================] - 0s 937us/step - loss: 0.0683 - accuracy: 0.9781\n","Epoch 71/200\n","33/33 [==============================] - 0s 865us/step - loss: 0.0679 - accuracy: 0.9795\n","Epoch 72/200\n","33/33 [==============================] - 0s 912us/step - loss: 0.0652 - accuracy: 0.9808\n","Epoch 73/200\n","33/33 [==============================] - 0s 853us/step - loss: 0.0663 - accuracy: 0.9821\n","Epoch 74/200\n","33/33 [==============================] - 0s 837us/step - loss: 0.0624 - accuracy: 0.9817\n","Epoch 75/200\n","33/33 [==============================] - 0s 726us/step - loss: 0.0659 - accuracy: 0.9806\n","Epoch 76/200\n","33/33 [==============================] - 0s 754us/step - loss: 0.0652 - accuracy: 0.9803\n","Epoch 77/200\n","33/33 [==============================] - 0s 730us/step - loss: 0.0676 - accuracy: 0.9806\n","Epoch 78/200\n","33/33 [==============================] - 0s 782us/step - loss: 0.0618 - accuracy: 0.9828\n","Epoch 79/200\n","33/33 [==============================] - 0s 705us/step - loss: 0.0631 - accuracy: 0.9815\n","Epoch 80/200\n","33/33 [==============================] - 0s 735us/step - loss: 0.0623 - accuracy: 0.9832\n","Epoch 81/200\n","33/33 [==============================] - 0s 750us/step - loss: 0.0653 - accuracy: 0.9812\n","Epoch 82/200\n","33/33 [==============================] - 0s 909us/step - loss: 0.0612 - accuracy: 0.9831\n","Epoch 83/200\n","33/33 [==============================] - 0s 831us/step - loss: 0.0620 - accuracy: 0.9821\n","Epoch 84/200\n","33/33 [==============================] - 0s 721us/step - loss: 0.0631 - accuracy: 0.9811\n","Epoch 85/200\n","33/33 [==============================] - 0s 768us/step - loss: 0.0637 - accuracy: 0.9825\n","Epoch 86/200\n","33/33 [==============================] - 0s 770us/step - loss: 0.0606 - accuracy: 0.9835\n","Epoch 87/200\n","33/33 [==============================] - 0s 783us/step - loss: 0.0588 - accuracy: 0.9840\n","Epoch 88/200\n","33/33 [==============================] - 0s 839us/step - loss: 0.0663 - accuracy: 0.9808\n","Epoch 89/200\n","33/33 [==============================] - 0s 801us/step - loss: 0.0629 - accuracy: 0.9809\n","Epoch 90/200\n","33/33 [==============================] - 0s 844us/step - loss: 0.0616 - accuracy: 0.9811\n","Epoch 91/200\n","33/33 [==============================] - 0s 948us/step - loss: 0.0595 - accuracy: 0.9829\n","Epoch 92/200\n","33/33 [==============================] - 0s 717us/step - loss: 0.0585 - accuracy: 0.9835\n","Epoch 93/200\n","33/33 [==============================] - 0s 794us/step - loss: 0.0603 - accuracy: 0.9828\n","Epoch 94/200\n","33/33 [==============================] - 0s 738us/step - loss: 0.0613 - accuracy: 0.9821\n","Epoch 95/200\n","33/33 [==============================] - 0s 802us/step - loss: 0.0640 - accuracy: 0.9811\n","Epoch 96/200\n","33/33 [==============================] - 0s 770us/step - loss: 0.0607 - accuracy: 0.9835\n","Epoch 97/200\n","33/33 [==============================] - 0s 729us/step - loss: 0.0584 - accuracy: 0.9838\n","Epoch 98/200\n","33/33 [==============================] - 0s 811us/step - loss: 0.0588 - accuracy: 0.9828\n","Epoch 99/200\n","33/33 [==============================] - 0s 779us/step - loss: 0.0630 - accuracy: 0.9817\n","Epoch 100/200\n","33/33 [==============================] - 0s 855us/step - loss: 0.0588 - accuracy: 0.9832\n","Epoch 101/200\n","33/33 [==============================] - 0s 890us/step - loss: 0.0580 - accuracy: 0.9829\n","Epoch 102/200\n","33/33 [==============================] - 0s 892us/step - loss: 0.0634 - accuracy: 0.9806\n","Epoch 103/200\n","33/33 [==============================] - 0s 774us/step - loss: 0.0585 - accuracy: 0.9834\n","Epoch 104/200\n","33/33 [==============================] - 0s 835us/step - loss: 0.0592 - accuracy: 0.9831\n","Epoch 105/200\n","33/33 [==============================] - 0s 713us/step - loss: 0.0584 - accuracy: 0.9838\n","Epoch 106/200\n","33/33 [==============================] - 0s 723us/step - loss: 0.0582 - accuracy: 0.9834\n","Epoch 107/200\n","33/33 [==============================] - 0s 776us/step - loss: 0.0600 - accuracy: 0.9821\n","Epoch 108/200\n","33/33 [==============================] - 0s 712us/step - loss: 0.0616 - accuracy: 0.9832\n","Epoch 109/200\n","33/33 [==============================] - 0s 701us/step - loss: 0.0592 - accuracy: 0.9831\n","Epoch 110/200\n","33/33 [==============================] - 0s 710us/step - loss: 0.0593 - accuracy: 0.9831\n","Epoch 111/200\n","33/33 [==============================] - 0s 773us/step - loss: 0.0573 - accuracy: 0.9837\n","Epoch 112/200\n","33/33 [==============================] - 0s 707us/step - loss: 0.0574 - accuracy: 0.9840\n","Epoch 113/200\n","33/33 [==============================] - 0s 756us/step - loss: 0.0587 - accuracy: 0.9828\n","Epoch 114/200\n","33/33 [==============================] - 0s 798us/step - loss: 0.0578 - accuracy: 0.9846\n","Epoch 115/200\n","33/33 [==============================] - 0s 758us/step - loss: 0.0561 - accuracy: 0.9857\n","Epoch 116/200\n","33/33 [==============================] - 0s 761us/step - loss: 0.0558 - accuracy: 0.9834\n","Epoch 117/200\n","33/33 [==============================] - 0s 771us/step - loss: 0.0554 - accuracy: 0.9832\n","Epoch 118/200\n","33/33 [==============================] - 0s 722us/step - loss: 0.0562 - accuracy: 0.9845\n","Epoch 119/200\n","33/33 [==============================] - 0s 731us/step - loss: 0.0561 - accuracy: 0.9845\n","Epoch 120/200\n","33/33 [==============================] - 0s 737us/step - loss: 0.0552 - accuracy: 0.9848\n","Epoch 121/200\n","33/33 [==============================] - 0s 743us/step - loss: 0.0570 - accuracy: 0.9841\n","Epoch 122/200\n","33/33 [==============================] - 0s 760us/step - loss: 0.0560 - accuracy: 0.9845\n","Epoch 123/200\n","33/33 [==============================] - 0s 775us/step - loss: 0.0555 - accuracy: 0.9835\n","Epoch 124/200\n","33/33 [==============================] - 0s 852us/step - loss: 0.0544 - accuracy: 0.9855\n","Epoch 125/200\n","33/33 [==============================] - 0s 754us/step - loss: 0.0565 - accuracy: 0.9845\n","Epoch 126/200\n","33/33 [==============================] - 0s 794us/step - loss: 0.0558 - accuracy: 0.9851\n","Epoch 127/200\n","33/33 [==============================] - 0s 771us/step - loss: 0.0583 - accuracy: 0.9845\n","Epoch 128/200\n","33/33 [==============================] - 0s 770us/step - loss: 0.0567 - accuracy: 0.9838\n","Epoch 129/200\n","33/33 [==============================] - 0s 702us/step - loss: 0.0548 - accuracy: 0.9852\n","Epoch 130/200\n","33/33 [==============================] - 0s 727us/step - loss: 0.0587 - accuracy: 0.9829\n","Epoch 131/200\n","33/33 [==============================] - 0s 710us/step - loss: 0.0555 - accuracy: 0.9843\n","Epoch 132/200\n","33/33 [==============================] - 0s 740us/step - loss: 0.0565 - accuracy: 0.9831\n","Epoch 133/200\n","33/33 [==============================] - 0s 722us/step - loss: 0.0563 - accuracy: 0.9832\n","Epoch 134/200\n","33/33 [==============================] - 0s 733us/step - loss: 0.0541 - accuracy: 0.9857\n","Epoch 135/200\n","33/33 [==============================] - 0s 743us/step - loss: 0.0534 - accuracy: 0.9865\n","Epoch 136/200\n","33/33 [==============================] - 0s 867us/step - loss: 0.0542 - accuracy: 0.9851\n","Epoch 137/200\n","33/33 [==============================] - 0s 782us/step - loss: 0.0591 - accuracy: 0.9840\n","Epoch 138/200\n","33/33 [==============================] - 0s 742us/step - loss: 0.0556 - accuracy: 0.9843\n","Epoch 139/200\n","33/33 [==============================] - 0s 706us/step - loss: 0.0545 - accuracy: 0.9851\n","Epoch 140/200\n","33/33 [==============================] - 0s 741us/step - loss: 0.0564 - accuracy: 0.9840\n","Epoch 141/200\n","33/33 [==============================] - 0s 716us/step - loss: 0.0546 - accuracy: 0.9848\n","Epoch 142/200\n","33/33 [==============================] - 0s 747us/step - loss: 0.0522 - accuracy: 0.9863\n","Epoch 143/200\n","33/33 [==============================] - 0s 694us/step - loss: 0.0570 - accuracy: 0.9831\n","Epoch 144/200\n","33/33 [==============================] - 0s 785us/step - loss: 0.0535 - accuracy: 0.9851\n","Epoch 145/200\n","33/33 [==============================] - 0s 761us/step - loss: 0.0580 - accuracy: 0.9826\n","Epoch 146/200\n","33/33 [==============================] - 0s 703us/step - loss: 0.0546 - accuracy: 0.9849\n","Epoch 147/200\n","33/33 [==============================] - 0s 687us/step - loss: 0.0581 - accuracy: 0.9832\n","Epoch 148/200\n","33/33 [==============================] - 0s 706us/step - loss: 0.0568 - accuracy: 0.9858\n","Epoch 149/200\n","33/33 [==============================] - 0s 803us/step - loss: 0.0628 - accuracy: 0.9817\n","Epoch 150/200\n","33/33 [==============================] - 0s 712us/step - loss: 0.0604 - accuracy: 0.9829\n","Epoch 151/200\n","33/33 [==============================] - 0s 888us/step - loss: 0.0533 - accuracy: 0.9857\n","Epoch 152/200\n","33/33 [==============================] - 0s 722us/step - loss: 0.0543 - accuracy: 0.9857\n","Epoch 153/200\n","33/33 [==============================] - 0s 686us/step - loss: 0.0539 - accuracy: 0.9865\n","Epoch 154/200\n","33/33 [==============================] - 0s 697us/step - loss: 0.0522 - accuracy: 0.9852\n","Epoch 155/200\n","33/33 [==============================] - 0s 730us/step - loss: 0.0528 - accuracy: 0.9854\n","Epoch 156/200\n","33/33 [==============================] - 0s 747us/step - loss: 0.0523 - accuracy: 0.9854\n","Epoch 157/200\n","33/33 [==============================] - 0s 750us/step - loss: 0.0524 - accuracy: 0.9857\n","Epoch 158/200\n","33/33 [==============================] - 0s 696us/step - loss: 0.0536 - accuracy: 0.9848\n","Epoch 159/200\n","33/33 [==============================] - 0s 836us/step - loss: 0.0547 - accuracy: 0.9852\n","Epoch 160/200\n","33/33 [==============================] - 0s 798us/step - loss: 0.0520 - accuracy: 0.9861\n","Epoch 161/200\n","33/33 [==============================] - 0s 793us/step - loss: 0.0517 - accuracy: 0.9869\n","Epoch 162/200\n","33/33 [==============================] - 0s 805us/step - loss: 0.0534 - accuracy: 0.9849\n","Epoch 163/200\n","33/33 [==============================] - 0s 804us/step - loss: 0.0556 - accuracy: 0.9837\n","Epoch 164/200\n","33/33 [==============================] - 0s 761us/step - loss: 0.0524 - accuracy: 0.9866\n","Epoch 165/200\n","33/33 [==============================] - 0s 756us/step - loss: 0.0526 - accuracy: 0.9848\n","Epoch 166/200\n","33/33 [==============================] - 0s 778us/step - loss: 0.0525 - accuracy: 0.9860\n","Epoch 167/200\n","33/33 [==============================] - 0s 832us/step - loss: 0.0571 - accuracy: 0.9834\n","Epoch 168/200\n","33/33 [==============================] - 0s 876us/step - loss: 0.0600 - accuracy: 0.9828\n","Epoch 169/200\n","33/33 [==============================] - 0s 794us/step - loss: 0.0599 - accuracy: 0.9826\n","Epoch 170/200\n","33/33 [==============================] - 0s 787us/step - loss: 0.0544 - accuracy: 0.9854\n","Epoch 171/200\n","33/33 [==============================] - 0s 722us/step - loss: 0.0547 - accuracy: 0.9848\n","Epoch 172/200\n","33/33 [==============================] - 0s 751us/step - loss: 0.0534 - accuracy: 0.9851\n","Epoch 173/200\n","33/33 [==============================] - 0s 729us/step - loss: 0.0531 - accuracy: 0.9846\n","Epoch 174/200\n","33/33 [==============================] - 0s 701us/step - loss: 0.0531 - accuracy: 0.9855\n","Epoch 175/200\n","33/33 [==============================] - 0s 753us/step - loss: 0.0521 - accuracy: 0.9843\n","Epoch 176/200\n","33/33 [==============================] - 0s 752us/step - loss: 0.0542 - accuracy: 0.9848\n","Epoch 177/200\n","33/33 [==============================] - 0s 823us/step - loss: 0.0524 - accuracy: 0.9858\n","Epoch 178/200\n","33/33 [==============================] - 0s 776us/step - loss: 0.0521 - accuracy: 0.9843\n","Epoch 179/200\n","33/33 [==============================] - 0s 726us/step - loss: 0.0531 - accuracy: 0.9843\n","Epoch 180/200\n","33/33 [==============================] - 0s 735us/step - loss: 0.0532 - accuracy: 0.9857\n","Epoch 181/200\n","33/33 [==============================] - 0s 1ms/step - loss: 0.0530 - accuracy: 0.9849\n","Epoch 182/200\n","33/33 [==============================] - 0s 874us/step - loss: 0.0520 - accuracy: 0.9865\n","Epoch 183/200\n","33/33 [==============================] - 0s 783us/step - loss: 0.0529 - accuracy: 0.9852\n","Epoch 184/200\n","33/33 [==============================] - 0s 770us/step - loss: 0.0508 - accuracy: 0.9861\n","Epoch 185/200\n","33/33 [==============================] - 0s 789us/step - loss: 0.0506 - accuracy: 0.9865\n","Epoch 186/200\n","33/33 [==============================] - 0s 778us/step - loss: 0.0501 - accuracy: 0.9858\n","Epoch 187/200\n","33/33 [==============================] - 0s 820us/step - loss: 0.0521 - accuracy: 0.9861\n","Epoch 188/200\n","33/33 [==============================] - 0s 762us/step - loss: 0.0515 - accuracy: 0.9865\n","Epoch 189/200\n","33/33 [==============================] - 0s 794us/step - loss: 0.0516 - accuracy: 0.9866\n","Epoch 190/200\n","33/33 [==============================] - 0s 746us/step - loss: 0.0527 - accuracy: 0.9854\n","Epoch 191/200\n","33/33 [==============================] - 0s 768us/step - loss: 0.0520 - accuracy: 0.9861\n","Epoch 192/200\n","33/33 [==============================] - 0s 726us/step - loss: 0.0512 - accuracy: 0.9861\n","Epoch 193/200\n","33/33 [==============================] - 0s 722us/step - loss: 0.0514 - accuracy: 0.9860\n","Epoch 194/200\n","33/33 [==============================] - 0s 738us/step - loss: 0.0530 - accuracy: 0.9857\n","Epoch 195/200\n","33/33 [==============================] - 0s 779us/step - loss: 0.0522 - accuracy: 0.9857\n","Epoch 196/200\n","33/33 [==============================] - 0s 802us/step - loss: 0.0535 - accuracy: 0.9849\n","Epoch 197/200\n","33/33 [==============================] - 0s 779us/step - loss: 0.0556 - accuracy: 0.9840\n","Epoch 198/200\n","33/33 [==============================] - 0s 831us/step - loss: 0.0555 - accuracy: 0.9848\n","Epoch 199/200\n","33/33 [==============================] - 0s 717us/step - loss: 0.0523 - accuracy: 0.9851\n","Epoch 200/200\n","33/33 [==============================] - 0s 772us/step - loss: 0.0509 - accuracy: 0.9857\n","204/204 [==============================] - 0s 545us/step - loss: 0.0507 - accuracy: 0.9871\n","\n"," Accuracy: 0.9871\n"],"name":"stdout"}]}]}